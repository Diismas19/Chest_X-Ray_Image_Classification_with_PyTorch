{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1: Custom CNN from Scratch"
      ],
      "metadata": {
        "id": "4TCX3secdLcm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "Jt77CkdodUAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "id": "kYfL_vh3VM3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import zipfile\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.transforms import v2\n",
        "from torchinfo import summary\n",
        "from tqdm.auto import tqdm\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "P-hRqFSSU3xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Dataset"
      ],
      "metadata": {
        "id": "KVaJqLdldY00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"alsaniipe/chest-x-ray-image\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "os.listdir(path)"
      ],
      "metadata": {
        "id": "9NuRW49aOvps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "0hYknVGCdgMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/kaggle/input/chest-x-ray-image'\n",
        "data_dir = os.path.join(base_path, 'Data')\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "\n",
        "print(f\"Directory: {train_dir}\\n\") # check the directory\n",
        "\n",
        "classes = [d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))]\n",
        "print(f\"Classes: {classes}\\n\") # check classes\n",
        "\n",
        "num_classes = len(classes)\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "for i, class_name in enumerate(classes):\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "\n",
        "    random_image_name = random.choice(os.listdir(class_dir))\n",
        "    image_path = os.path.join(class_dir, random_image_name)\n",
        "\n",
        "    file_size_kb = os.path.getsize(image_path) / 1024\n",
        "    file_type = os.path.splitext(random_image_name)[1]\n",
        "\n",
        "    with Image.open(image_path) as img:\n",
        "        width, height = img.size\n",
        "        mode = img.mode\n",
        "\n",
        "        ax = plt.subplot(1, num_classes, i + 1)\n",
        "        plt.imshow(img, cmap='gray')\n",
        "\n",
        "        title_text = (\n",
        "            f\"Class: {class_name}\\n\"\n",
        "            f\"Dimensions: {width}x{height} | Mode: {mode}\\n\"\n",
        "            f\"Type: {file_type} | Size: {file_size_kb:.2f} KB\"\n",
        "        )\n",
        "        plt.title(title_text, fontsize=10)\n",
        "        plt.axis('off')\n",
        "\n",
        "plt.suptitle(\"Examples of each class from dataset\", fontsize=16)\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m1rb9a0ldjoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train, validation and test dataset"
      ],
      "metadata": {
        "id": "HJRAibQWgQee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando o dispositivo: {device}\") # check\n",
        "\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "TRAIN_RATIO = 0.8\n",
        "\n",
        "def load_img(path):\n",
        "    img = Image.open(path).convert('RGB') # make sure that the image have the three channels\n",
        "    img = v2.functional.to_image(img) # convert to a pytorch tensor\n",
        "    img = v2.functional.to_dtype(img, dtype=torch.uint8, scale=True) # make sure that the image has 8 bits\n",
        "    return img\n",
        "\n",
        "minimal_transforms = v2.Compose([\n",
        "    v2.Resize((IMG_SIZE, IMG_SIZE)), # all images become 244 x 244\n",
        "    v2.ToDtype(torch.float32, scale=True) # transform in a float between 0 and 1\n",
        "])\n",
        "\n",
        "initial_train_dataset = ImageFolder(root=train_dir, transform=minimal_transforms, loader=load_img)\n",
        "test_dataset = ImageFolder(root=test_dir, transform=minimal_transforms, loader=load_img)\n",
        "\n",
        "class_names = initial_train_dataset.classes\n",
        "\n",
        "num_train_samples = len(initial_train_dataset)\n",
        "train_size = int(num_train_samples * TRAIN_RATIO)\n",
        "val_size = num_train_samples - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(initial_train_dataset, [train_size, val_size])\n",
        "print(f\"\\nTrain dataset: {len(train_dataset)}\\nValidation dataset: {len(val_dataset)}.\")\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "1ckRyyEBgWAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data augmentation"
      ],
      "metadata": {
        "id": "-wpQ6DDEkMF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transforms = v2.Compose([\n",
        "    v2.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    v2.RandomHorizontalFlip(p=0.5),\n",
        "    v2.RandomRotation(degrees=10),\n",
        "    v2.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "train_dataset.dataset.transform = train_transforms # only on train dataset"
      ],
      "metadata": {
        "id": "JoxVph0sFno0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformations for validation and test"
      ],
      "metadata": {
        "id": "KUdSY2OnJQYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_test_transforms = v2.Compose([\n",
        "    v2.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "val_dataset.dataset.transform = val_test_transforms\n",
        "test_dataset.transform = val_test_transforms"
      ],
      "metadata": {
        "id": "C6OlyacdK1iK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloaders"
      ],
      "metadata": {
        "id": "A37eDuD7LMgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,  # Shuffle in each epoch\n",
        "    num_workers=2, # paralelization\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"Batches in train_loader: {len(train_loader)}\")\n",
        "print(f\"Batches in val_loader: {len(val_loader)}\")\n",
        "print(f\"Batches in test_loader: {len(test_loader)}\")"
      ],
      "metadata": {
        "id": "oMp_B8SQLTkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Architecture of the model"
      ],
      "metadata": {
        "id": "O9PiYECLhbvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we define the architecture for our custom CNN. It consists of three convolutional blocks for feature extraction and a classifier head with a dropout layer to prevent overfitting."
      ],
      "metadata": {
        "id": "9TsoNZ7nvEjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 3\n",
        "\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CustomCNN, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            # first layer\n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # Image -> 112x112\n",
        "\n",
        "            # second layer\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # Image -> 56x56\n",
        "\n",
        "            # third layer\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)  # Imagem -> 28x28\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            # 64 x 28 x 28\n",
        "            nn.Linear(in_features=64 * 28 * 28, out_features=512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5), # Dropout\n",
        "            nn.Linear(in_features=512, out_features=num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "custom_model = CustomCNN(num_classes=NUM_CLASSES)\n",
        "\n",
        "custom_model.to(device)\n",
        "\n",
        "# check the model\n",
        "summary(custom_model, input_size=(BATCH_SIZE, 3, IMG_SIZE, IMG_SIZE))"
      ],
      "metadata": {
        "id": "sKn9H8PThfKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions for training and evaluation"
      ],
      "metadata": {
        "id": "GNv5yc11L86o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model: nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device):\n",
        "    \"\"\"Execute a train epoch\"\"\"\n",
        "    model.train()\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        y_pred_logits = model(X) # forward\n",
        "\n",
        "        # evaluate loss\n",
        "        loss = loss_fn(y_pred_logits, y)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # evaluate gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # backprop\n",
        "        loss.backward()\n",
        "\n",
        "        # update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # evaluate accuracy\n",
        "        y_pred_class = torch.argmax(torch.softmax(y_pred_logits, dim=1), dim=1)\n",
        "        train_acc += (y_pred_class == y).sum().item() / len(y_pred_logits)\n",
        "\n",
        "    # update metrics\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    train_acc = train_acc / len(dataloader)\n",
        "    return train_loss, train_acc\n",
        "\n",
        "def eval_step(model: nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: nn.Module,\n",
        "              device: torch.device):\n",
        "    \"\"\"Execute an avaliation epoch.\"\"\"\n",
        "    model.eval()\n",
        "    eval_loss, eval_acc = 0, 0\n",
        "\n",
        "    with torch.inference_mode(): # no grads\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            eval_pred_logits = model(X)\n",
        "\n",
        "            loss = loss_fn(eval_pred_logits, y)\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            eval_pred_class = torch.argmax(torch.softmax(eval_pred_logits, dim=1), dim=1)\n",
        "            eval_acc += (eval_pred_class == y).sum().item() / len(eval_pred_logits)\n",
        "\n",
        "    eval_loss = eval_loss / len(dataloader)\n",
        "    eval_acc = eval_acc / len(dataloader)\n",
        "    return eval_loss, eval_acc\n",
        "\n",
        "def train(model: nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          val_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device):\n",
        "    \"\"\"Train and evaluate the model.\"\"\"\n",
        "    results = {\n",
        "        \"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"val_loss\": [],\n",
        "        \"val_acc\": []\n",
        "    }\n",
        "\n",
        "    # main loop\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                           dataloader=train_dataloader,\n",
        "                                           loss_fn=loss_fn,\n",
        "                                           optimizer=optimizer,\n",
        "                                           device=device)\n",
        "\n",
        "        val_loss, val_acc = eval_step(model=model,\n",
        "                                        dataloader=val_dataloader,\n",
        "                                        loss_fn=loss_fn,\n",
        "                                        device=device)\n",
        "\n",
        "        # show the results for each epoch\n",
        "        print(\n",
        "            f\"Época: {epoch+1} | \"\n",
        "            f\"Train loss: {train_loss:.4f} | \"\n",
        "            f\"Train acc: {train_acc:.4f} | \"\n",
        "            f\"Val loss: {val_loss:.4f} | \"\n",
        "            f\"Val acc: {val_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"val_loss\"].append(val_loss)\n",
        "        results[\"val_acc\"].append(val_acc)\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "HC2kQTTZMBaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "y5LfVLGmVYzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(params=custom_model.parameters(), lr=0.0001)\n",
        "\n",
        "NUM_EPOCHS = 15\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "custom_model_results = train(model=custom_model,\n",
        "                             train_dataloader=train_loader,\n",
        "                             val_dataloader=val_loader,\n",
        "                             optimizer=optimizer,\n",
        "                             loss_fn=loss_fn,\n",
        "                             epochs=NUM_EPOCHS,\n",
        "                             device=device)\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(f\"Training last {total_time:.2f} seconds.\")"
      ],
      "metadata": {
        "id": "12WyjNA2VewS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = \"models/custom_cnn.pth\"\n",
        "torch.save(obj=custom_model.state_dict(), f=MODEL_PATH)"
      ],
      "metadata": {
        "id": "fdkNtydZkA3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate performance"
      ],
      "metadata": {
        "id": "Jc_Tg6yNOlfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_cnn_results = custom_model_results\n",
        "\n",
        "def plot_loss_curves(results: dict[str, list[float]]):\n",
        "\n",
        "    loss = results['train_loss']\n",
        "    val_loss = results['val_loss']\n",
        "    accuracy = results['train_acc']\n",
        "    val_accuracy = results['val_acc']\n",
        "    epochs = range(len(results['train_loss']))\n",
        "\n",
        "    plt.figure(figsize=(15, 7))\n",
        "\n",
        "    # loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, loss, label='train_loss')\n",
        "    plt.plot(epochs, val_loss, label='val_loss')\n",
        "    plt.title('Loss Curves')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    # accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, accuracy, label='train_accuracy')\n",
        "    plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "    plt.title('Accuracy Curves')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_loss_curves(custom_cnn_results)"
      ],
      "metadata": {
        "id": "ld07WAbnOrIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation_metrics_report(model: torch.nn.Module,\n",
        "                              dataloader: torch.utils.data.DataLoader,\n",
        "                              class_names: list[str],\n",
        "                              device: torch.device):\n",
        "\n",
        "    model.eval()\n",
        "    y_true_list = []\n",
        "    y_preds_list = []\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for X, y in tqdm(dataloader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_logits = model(X)\n",
        "            y_pred_labels = torch.argmax(y_logits, dim=1)\n",
        "\n",
        "            y_true_list.append(y.cpu())\n",
        "            y_preds_list.append(y_pred_labels.cpu())\n",
        "\n",
        "    y_true = torch.cat(y_true_list).numpy()\n",
        "    y_preds = torch.cat(y_preds_list).numpy()\n",
        "\n",
        "    report_dict = classification_report(y_true,\n",
        "                                        y_preds,\n",
        "                                        target_names=class_names,\n",
        "                                        output_dict=True,\n",
        "                                        zero_division=0)\n",
        "\n",
        "    df_report = pd.DataFrame(report_dict).T.round(4)\n",
        "\n",
        "    return df_report, y_true, y_preds\n",
        "\n",
        "loaded_model_custom = CustomCNN(num_classes=NUM_CLASSES).to(device)\n",
        "loaded_model_custom.load_state_dict(torch.load(MODEL_PATH))\n",
        "\n",
        "df_report_custom, _, _ = evaluation_metrics_report(\n",
        "    model=loaded_model_custom,\n",
        "    dataloader=test_loader,\n",
        "    class_names=class_names,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(\"\\nCustom CNN\")\n",
        "print(df_report_custom)"
      ],
      "metadata": {
        "id": "mvGB1ID_PJWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2: Feature Extraction with a Pre-trained ResNet-18"
      ],
      "metadata": {
        "id": "DGlLHl6FO06G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the second model, we'll use a pre-trained ResNet-18. We start by loading the model with its ImageNet weights, freezing all its layers, and then replacing the final classifier layer with one suited for our 3 classes. This technique is known as Feature Extraction."
      ],
      "metadata": {
        "id": "3OTwcB5WvLrQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model"
      ],
      "metadata": {
        "id": "VGAQxHmJU12F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_fe = models.resnet18(weights=\"IMAGENET1K_V1\")"
      ],
      "metadata": {
        "id": "SULu185XPN8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Freeze convolutional layers and replace classifier"
      ],
      "metadata": {
        "id": "Mb9SuBNVVIWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model_fe.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "num_ftrs = model_fe.fc.in_features\n",
        "\n",
        "model_fe.fc = nn.Linear(in_features=num_ftrs, out_features=NUM_CLASSES)\n",
        "\n",
        "model_fe = model_fe.to(device)"
      ],
      "metadata": {
        "id": "1iWKavQUVKOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "31YzA2mKWVkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_fe = optim.Adam(params=model_fe.parameters(), lr=0.001)\n",
        "# same loss function\n",
        "\n",
        "NUM_EPOCHS_FE = 10\n",
        "start_time_fe = time.time()\n",
        "\n",
        "model_fe_results = train(model=model_fe,\n",
        "                         train_dataloader=train_loader,\n",
        "                         val_dataloader=val_loader,\n",
        "                         optimizer=optimizer_fe,\n",
        "                         loss_fn=loss_fn,\n",
        "                         epochs=NUM_EPOCHS_FE,\n",
        "                         device=device)\n",
        "\n",
        "end_time_fe = time.time()\n",
        "\n",
        "total_time_fe = end_time_fe - start_time_fe\n",
        "print(f\"Training last {total_time_fe:.2f} seconds\")"
      ],
      "metadata": {
        "id": "mdCdx2mYWeBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_FE_PATH = \"models/resnet18_feature_extraction.pth\"\n",
        "torch.save(obj=model_fe.state_dict(), f=MODEL_FE_PATH)"
      ],
      "metadata": {
        "id": "LoOSWtM8dPIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate performance"
      ],
      "metadata": {
        "id": "ULsSEt8VdX32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(model_fe_results)"
      ],
      "metadata": {
        "id": "xAk_gAhddZuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_fe = models.resnet18()\n",
        "num_ftrs_fe = loaded_model_fe.fc.in_features\n",
        "loaded_model_fe.fc = nn.Linear(num_ftrs_fe, NUM_CLASSES)\n",
        "loaded_model_fe.to(device)\n",
        "\n",
        "loaded_model_fe.load_state_dict(torch.load(MODEL_FE_PATH))\n",
        "\n",
        "df_report_fe, _, _ = evaluation_metrics_report(\n",
        "    model=loaded_model_fe,\n",
        "    dataloader=test_loader,\n",
        "    class_names=class_names,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(\"\\nFeature Extraction\")\n",
        "print(df_report_fe)"
      ],
      "metadata": {
        "id": "4Fqbat7Cd_fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 3: Fine-Tuning the Pre-trained ResNet-18"
      ],
      "metadata": {
        "id": "wAppNqPqeWxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final approach is fine-tuning. We will again load a pre-trained ResNet-18 and replace its classifier. However, this time we will unfreeze all the layers and train the entire network with a very low learning rate to adapt its learned features to our X-ray dataset."
      ],
      "metadata": {
        "id": "QaKTPGDPvWzO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load model"
      ],
      "metadata": {
        "id": "CqsgHKcPhTvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
        "\n",
        "num_ftrs_ft = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(in_features=num_ftrs_ft, out_features=NUM_CLASSES)\n",
        "model_ft = model_ft.to(device)"
      ],
      "metadata": {
        "id": "kFdbnWdofI7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "wZzpaTi1hqSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_ft = optim.Adam(params=model_ft.parameters(), lr=0.0001)\n",
        "# same loss function\n",
        "\n",
        "NUM_EPOCHS_FT = 5\n",
        "\n",
        "start_time_ft = time.time()\n",
        "\n",
        "model_ft_results = train(model=model_ft,\n",
        "                         train_dataloader=train_loader,\n",
        "                         val_dataloader=val_loader,\n",
        "                         optimizer=optimizer_ft,\n",
        "                         loss_fn=loss_fn,\n",
        "                         epochs=NUM_EPOCHS_FT,\n",
        "                         device=device)\n",
        "\n",
        "end_time_ft = time.time()\n",
        "\n",
        "total_time_ft = end_time_ft - start_time_ft\n",
        "print(f\"Training last {total_time_ft:.2f} seconds.\")"
      ],
      "metadata": {
        "id": "Nhxz8j4ghr2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_FT_PATH = \"models/resnet18_fine_tuning.pth\"\n",
        "torch.save(obj=model_ft.state_dict(), f=MODEL_FT_PATH)"
      ],
      "metadata": {
        "id": "2StBrVp8oQk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate performance"
      ],
      "metadata": {
        "id": "t0kDkpySoYrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(model_ft_results)"
      ],
      "metadata": {
        "id": "QL1TQORLobDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_ft = models.resnet18()\n",
        "num_ftrs_ft = loaded_model_ft.fc.in_features\n",
        "loaded_model_ft.fc = nn.Linear(num_ftrs_ft, NUM_CLASSES)\n",
        "loaded_model_ft.to(device)\n",
        "\n",
        "loaded_model_ft.load_state_dict(torch.load(MODEL_FT_PATH))\n",
        "\n",
        "df_report_ft, y_true_ft, y_preds_ft = evaluation_metrics_report(\n",
        "    model=loaded_model_ft,\n",
        "    dataloader=test_loader,\n",
        "    class_names=class_names,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(\"\\nAvaliação Fine-Tuning\")\n",
        "print(df_report_ft)"
      ],
      "metadata": {
        "id": "u9SWwAwCoczs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Model Comparison"
      ],
      "metadata": {
        "id": "dbQMXdlVwZAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Model | Accuracy | Precision (Macro) | Recall (Macro) | F1-Score (Macro) |\n",
        "| :--- | :---: | :---: | :---: | :---: |\n",
        "| Custom CNN | 0.9581|\t0.9566|\t0.9554|\t0.9553|\n",
        "| Feature Extraction | 0.9348|\t0.9400|\t0.9174|\t0.9280|\n",
        "| **Fine-Tuning (ResNet-18)** |  **0.9658**|\t**0.9714**\t|**0.9453**|\t**0.9578**|\n",
        "\n",
        "As shown in the table, the fine-tuned ResNet-18 model achieved the best performance across all metrics. The detailed analysis and discussion can be found in the project's README.md."
      ],
      "metadata": {
        "id": "rDLEVdVBwbXG"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "4TCX3secdLcm",
        "Jt77CkdodUAG",
        "KVaJqLdldY00",
        "0hYknVGCdgMo",
        "HJRAibQWgQee",
        "-wpQ6DDEkMF2",
        "KUdSY2OnJQYK",
        "A37eDuD7LMgu",
        "O9PiYECLhbvd",
        "GNv5yc11L86o",
        "y5LfVLGmVYzg",
        "Jc_Tg6yNOlfz",
        "DGlLHl6FO06G",
        "VGAQxHmJU12F",
        "Mb9SuBNVVIWo",
        "31YzA2mKWVkG",
        "ULsSEt8VdX32",
        "wAppNqPqeWxf",
        "CqsgHKcPhTvq",
        "wZzpaTi1hqSv",
        "t0kDkpySoYrF",
        "dbQMXdlVwZAl"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}